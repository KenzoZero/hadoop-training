Create a table using hbase shell

create '/user/user01/voter_data_table', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'true'

hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,cf1:name,\
cf2:age,cf2:party,cf3:contribution_amount,\
cf3:voter_number \
-Dimporttsv.bulk.output=/user/user01/dummy \
/user/user01/voter_data_table \
/user/user01/voter1M


hbase shell 
alter '/user/user01/voter_data_table', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'false'

scan '/user/user01/voter_data_table', LIMIT => 5

create '/user/user01/voter_data_table_10m', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'true'

hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=cf1:number,HBASE_ROW_KEY,\
cf2:age,cf2:party,cf3:contribution_amount,\
cf3:voter_number \
-Dimporttsv.bulk.output=/user/user01/dummy2 \
/user/user01/voter_data_table_10m \
   /user/user01/voter10M

hbase shell 
alter '/user/user01/voter_data_table_10m', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'false'

scan '/user/user01/voter_data_table_10m', LIMIT => 5   

create '/user/user01/voter_data_table_cp', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'true'

hbase com.mapr.fs.hbase.mapreduce.CopyTable -src /user/user01/voter_data_table -dst /user/user01/voter_data_table_cp

alter '/user/user01/voter_data_table_cp', {NAME=>'cf1'}, {NAME=>'cf2'}, {NAME=>'cf3'}, BULKLOAD => 'false'

scan '/user/user01/voter_data_table_cp', LIMIT => 5

hbase com.mapr.fs.hbase.mapreduce.CopyTable -src /user/user01/voter_data_table_10m -dst /user/user01/voter_data_table_cp